---
title: "Gurpinder Singh"
author: "STAT 108"
date: "1/26/2022"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Load all the following library
```{r eval = TRUE}
library(tidyverse)
library(broom)
library(pROC)
library(plotROC)
library(arm)
library(knitr)
```
Exercise 1
```{r eval = TRUE}
spot <- read_csv("spotify.csv")
spot$target <- factor(spot$target)
spot <- spot %>% mutate(key = case_when(
           key == 2 ~ 'D',
           key == 3 ~ 'D#',
           key!=2 & key!=3 ~ "Other"))        

ggplot(data = spot, aes(x = key, fill = target)) + 
  geom_bar(position = "fill") + 
  labs(x = "Key Types",y = "Target Value", title = "Target-Key Comparison") +
  coord_flip()

```
The following compares the key types to the target value of 0 and 1. It showcasesw the percentage of target values in each key types. Additionally
Exercise 2:
Following source was referenced: https://stats.oarc.ucla.edu/r/dae/logit-regression/ for Exercise 2
```{r eval = TRUE}
model <- glm(target ~ acousticness+ danceability+ duration_ms+ instrumentalness+ loudness+ speechiness+ valence, data = spot, family = binomial)
tidy(model, conf.int = TRUE) %>% # output model
  kable(digits = 3) # format model output
```
Exercise 3:
```{r eval = TRUE}
model2 <- glm(target ~ acousticness+ danceability+ duration_ms+ instrumentalness+ loudness+ speechiness+ valence+key , data = spot, family = binomial)
tidy(model2, conf.int = TRUE) 
anova(model, model2, test = "Chisq")
summary(model)
summary(model2)
```
Using a chisquare test we see the p value is low so we can state that adding the variable key produces a very similar model to model without key. Looking at the AIC value inside of the summarry of the two models we can see that model2 produces a slightly better accuracy and thus we can state model2 with the key variable in it is the better model. 

Exercise 4:
```{r eval = TRUE}
tidy(model2, conf.int = TRUE) %>% # output model
  kable(digits = 3) # format model output
```
The value of target will decrease by 1.073 if the value of key is d#, aka value of key is 3
Exercise 5
```{r eval = TRUE}
print(model2)
aug <- augment(model2, type.predict = "response")
print(aug)
```
Exercise 6
```{r eval = TRUE}
arm::binnedplot(aug$.fitted ,aug$.resid, 
    xlab="Predictions", ylab="Average residual", 
    main="Prediction vs. Residual", col.int="gray")
```
Exercise 7
```{r eval = TRUE}
arm::binnedplot(aug$duration_ms ,aug$.resid, 
    xlab="Duration_ms", ylab="Average residual", 
    main="Duration_ms vs. Average residuals", col.int="gray")

```
Exercise 8
```{r eval = TRUE}
aug %>% 
  group_by(key) %>% 
  summarise(n = n(),mean = mean(.resid)) %>%
  kable(digits = 3) # format model output
```
Exersize 9:
There is no clear linear relationship as the residual vs predicted values plot showcases a u shape instead of a distinct linear line. So assumption is not satisfied.

Exersize 10:
The following source was refrenced: https://rdrr.io/cran/plotROC/man/geom_roc.html
```{r eval = TRUE}
plot(ggplot(aug, aes(d= as.numeric(target) - 1,m= .fitted)) +
  geom_roc(n.cuts = 15) +
  geom_abline(slope = 1, intercept = 0, size = 0.4) + 
  coord_equal() +
  theme_bw()+
  labs(x ="target-1",
       y = "fitted", 
       title = "Roc Curve"))
```
Exersize 11:
The model does effectively effectively differentiates between the songs the user likes versus those he doesnâ€™t.
Exersize 12:
I would choose a threshold value of .5725 as it is an inflection point on the curve where the True positive is maximized and false negative is small as possible. 

Excersize 13:
```{r eval = TRUE}
aug <-aug %>% mutate(prediction = case_when(
           .fitted >= .5725 ~ '1',
           .fitted < .5725 ~ '0',))
aug %>% 
  group_by(prediction) %>% 
  summarise(n = n()) %>%
  kable(digits = 3) # format model output

```
Excersize 14:
